{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.regularizers import L1L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"EMBEDDING_SIZE\": 32,\n",
    "    \n",
    "    \"ATTENTION_SIZE\": 8,\n",
    "    \"ATTENTION_MODULE\": \"additive\",\n",
    "    \"ATTENTION_METHOD\": \"standard\",\n",
    "    \n",
    "    \"LR\": 0.0005,\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"EPOCHS\": 30,\n",
    "}\n",
    "\n",
    "MODEL = f\"{config['ATTENTION_METHOD']}-{config['ATTENTION_MODULE']}-attention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_WANDB = False\n",
    "\n",
    "if(RUN_WANDB):\n",
    "    import wandb\n",
    "    from wandb.keras import WandbCallback\n",
    "    from secrets import WANDB\n",
    "    wandb.login(key=WANDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Data Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fold):\n",
    "    with open(f'./data/fold_{fold}.npy', mode='rb') as f:\n",
    "        train_inputs = np.load(f, allow_pickle=False)\n",
    "        train_target_inputs = np.load(f, allow_pickle=False) \n",
    "        train_targets = np.load(f, allow_pickle=False)\n",
    "        # val arrays\n",
    "        val_inputs = np.load(f, allow_pickle=False)\n",
    "        val_target_inputs = np.load(f, allow_pickle=False)\n",
    "        val_targets = np.load(f, allow_pickle=False)\n",
    "        # test arrays\n",
    "        test_inputs = np.load(f, allow_pickle=False)\n",
    "        test_target_inputs = np.load(f, allow_pickle=False)\n",
    "        test_targets = np.load(f, allow_pickle=False)\n",
    "        # data info\n",
    "        data_features = np.load(f, allow_pickle=False)\n",
    "    return (train_inputs,train_target_inputs), train_targets, (val_inputs,val_target_inputs), val_targets, (test_inputs,test_target_inputs), test_targets, data_features\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, data_features = get_data(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 10:41:42.779278: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-13 10:41:42.779544: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 72, 32) dtype=float32 (created by layer 'lstm_1')>, <KerasTensor: shape=(None, 32) dtype=float32 (created by layer 'lstm_1')>, <KerasTensor: shape=(None, 32) dtype=float32 (created by layer 'lstm_1')>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([InputSpec(shape=(None, 32), ndim=2), ListWrapper([InputSpec(shape=(None, 72, 32), ndim=3), InputSpec(shape=(None, 32), ndim=2), InputSpec(shape=(None, 32), ndim=2)])]); however `cell.state_size` is [32, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 183>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m], optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m--> 183\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msimple_encoder_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36msimple_encoder_decoder\u001b[0;34m(historical_shape, targets_shape)\u001b[0m\n\u001b[1;32m    119\u001b[0m cell \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEMBEDDING_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m    120\u001b[0m                               return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    121\u001b[0m                               return_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    122\u001b[0m                               recurrent_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglorot_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    123\u001b[0m                               activity_regularizer\u001b[38;5;241m=\u001b[39mL1L2(l1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m, l2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m))(historicals)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(cell)\n\u001b[0;32m--> 127\u001b[0m decoder \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEMBEDDING_SIZE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mreturn_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mrecurrent_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglorot_uniform\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mL1L2\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.000001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.000001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m encoder_outputs, hidden_state, cell_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENCODER_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m    135\u001b[0m                                                    return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    136\u001b[0m                                                    return_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    137\u001b[0m                                                    recurrent_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglorot_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    138\u001b[0m                                                    activity_regularizer\u001b[38;5;241m=\u001b[39mL1L2(l1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m, l2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m))(inputs)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mATTENTION_MODULE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditive\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/ml-ts-env/lib/python3.8/site-packages/keras/layers/rnn/base_rnn.py:562\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# Perform the call with temporarily replaced input_spec\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m full_input_spec\n\u001b[0;32m--> 562\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfull_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Remove the additional_specs from input spec and keep the rest. It is\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# important to keep since the input spec was populated by build(), and\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# will be reused in the stateful=True.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(additional_specs)]\n",
      "File \u001b[0;32m~/miniforge3/envs/ml-ts-env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/ml-ts-env/lib/python3.8/site-packages/keras/layers/rnn/base_rnn.py:477\u001b[0m, in \u001b[0;36mRNN._validate_state_spec\u001b[0;34m(cell_state_sizes, init_state_specs)\u001b[0m\n\u001b[1;32m    474\u001b[0m flat_state_specs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(init_state_specs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(flat_cell_state_sizes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(flat_state_specs):\n\u001b[0;32m--> 477\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell_state_spec, cell_state_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_state_specs,\n\u001b[1;32m    479\u001b[0m                                             flat_cell_state_sizes):\n\u001b[1;32m    480\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[1;32m    481\u001b[0m       \u001b[38;5;66;03m# Ignore the first axis for init_state which is for batch\u001b[39;00m\n\u001b[1;32m    482\u001b[0m       cell_state_spec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\u001b[38;5;241m.\u001b[39mis_compatible_with(\n\u001b[1;32m    483\u001b[0m           tf\u001b[38;5;241m.\u001b[39mTensorShape(cell_state_size)):\n",
      "\u001b[0;31mValueError\u001b[0m: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([InputSpec(shape=(None, 32), ndim=2), ListWrapper([InputSpec(shape=(None, 72, 32), ndim=3), InputSpec(shape=(None, 32), ndim=2), InputSpec(shape=(None, 32), ndim=2)])]); however `cell.state_size` is [32, 32]"
     ]
    }
   ],
   "source": [
    "class BahdanauAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, use_bias=False):\n",
    "        super(BahdanauAttentionLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.use_bias = use_bias\n",
    "        self.W1 = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "        self.W2 = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "    def get_config(self):\n",
    "        config = super(BahdanauAttentionLayer, self).get_config()\n",
    "        config.update({\"units\": self.units, \"use_bias\":self.use_bias})\n",
    "        return config\n",
    "    def call(self, query, values, keys=None, verbose=False):\n",
    "        expanded_query = tf.expand_dims(query, 2)\n",
    "        encoded_query = self.W1(expanded_query)\n",
    "        if(keys is None):\n",
    "            encoded_keys = self.W2(tf.expand_dims(values, 1))\n",
    "        else:\n",
    "            encoded_keys = self.W2(tf.expand_dims(keys, 1))\n",
    "        combined_encoded_query_and_keys = encoded_query + encoded_keys\n",
    "        tanh_score = tf.nn.tanh(combined_encoded_query_and_keys)\n",
    "        score = tf.reduce_sum(tanh_score, axis=-1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=-1)\n",
    "        overall_context_vector = tf.matmul(attention_weights, values)\n",
    "        context_vector = overall_context_vector\n",
    "        return context_vector\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, use_bias=False):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.units = units\n",
    "        self.use_bias = use_bias\n",
    "        self.W1 = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "        self.W2 = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    def get_config(self):\n",
    "        config = super(BahdanauAttention, self).get_config()\n",
    "        config.update({\"units\": self.units, \"use_bias\":self.use_bias})\n",
    "        return config\n",
    "    def call(self, query, values, keys=None, verbose=False):\n",
    "        query_with_time_axis = tf.expand_dims(query, 2)\n",
    "        encoded_query = self.W1(query_with_time_axis)\n",
    "        if(keys is None):\n",
    "            encoded_keys = self.W2(tf.expand_dims(values, 1))\n",
    "        else:\n",
    "            encoded_keys = self.W2(tf.expand_dims(keys, 1))\n",
    "        combined_encoded_query_and_keys = encoded_query + encoded_keys\n",
    "        tanh_score = tf.nn.tanh(combined_encoded_query_and_keys)\n",
    "        score = self.V(tanh_score)\n",
    "        squeezed_score = tf.squeeze(score, axis=-1)\n",
    "        attention_weights = tf.nn.softmax(squeezed_score, axis=-1)\n",
    "        context_vector = tf.matmul(attention_weights, values)\n",
    "        return context_vector\n",
    "    \n",
    "class LuongAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, use_bias=False):\n",
    "        super(BahdanauAttentionLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.use_bias = use_bias\n",
    "        self.W1 = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "        self.W2 = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "    def get_config(self):\n",
    "        config = super(BahdanauAttentionLayer, self).get_config()\n",
    "        config.update({\"units\": self.units, \"use_bias\":self.use_bias})\n",
    "        return config\n",
    "    def call(self, query, values, keys=None, verbose=False):\n",
    "        expanded_query = tf.expand_dims(query, 2)\n",
    "        encoded_query = self.W1(expanded_query)\n",
    "        if(keys is None):\n",
    "            encoded_keys = self.W2(tf.expand_dims(values, 1))\n",
    "        else:\n",
    "            keys = tf.expand_dims(keys, 1)\n",
    "            encoded_keys = self.W2(keys)\n",
    "        combined_encoded_query_and_keys = encoded_query * encoded_keys\n",
    "        tanh_score = tf.nn.tanh(combined_encoded_query_and_keys)\n",
    "        score = tf.reduce_sum(tanh_score, axis=-1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=-1)\n",
    "        overall_context_vector = tf.matmul(attention_weights, values)\n",
    "        context_vector = overall_context_vector\n",
    "        return context_vector\n",
    "\n",
    "class LuongAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, use_bias=False):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.units = units\n",
    "        self.use_bias = use_bias\n",
    "        self.W1 = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "        self.W2 = tf.keras.layers.Dense(self.units, use_bias=self.use_bias)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    def get_config(self):\n",
    "        config = super(BahdanauAttention, self).get_config()\n",
    "        config.update({\"units\": self.units, \"use_bias\":self.use_bias})\n",
    "        return config\n",
    "    def call(self, query, values, keys=None, verbose=False):\n",
    "        query_with_time_axis = tf.expand_dims(query, 2)\n",
    "        encoded_query = self.W1(query_with_time_axis)\n",
    "        if(keys is None):\n",
    "            encoded_keys = self.W2(tf.expand_dims(values, 1))\n",
    "        else:\n",
    "            keys = tf.expand_dims(keys, 1)\n",
    "            encoded_keys = self.W2(keys)\n",
    "        combined_encoded_query_and_keys = encoded_query * encoded_keys\n",
    "        tanh_score = tf.nn.tanh(combined_encoded_query_and_keys)\n",
    "        score = self.V(tanh_score)\n",
    "        squeezed_score = tf.squeeze(score, axis=-1)\n",
    "        attention_weights = tf.nn.softmax(squeezed_score, axis=-1)\n",
    "        context_vector = tf.matmul(attention_weights, values)\n",
    "        return context_vector\n",
    "\n",
    "def simple_encoder_decoder(historical_shape, targets_shape):\n",
    "    historicals = tf.keras.layers.Input(shape=historical_shape)\n",
    "    futures = tf.keras.layers.Input(shape=targets_shape)\n",
    "    \n",
    "    hidden = tf.keras.layers.LSTM(config[\"EMBEDDING_SIZE\"], \n",
    "                                  return_sequences=False, \n",
    "                                  return_state=False, \n",
    "                                  recurrent_initializer='glorot_uniform', \n",
    "                                  activity_regularizer=L1L2(l1=0.000001, l2=0.000001))(historicals)\n",
    "    \n",
    "    cell = tf.keras.layers.LSTM(config[\"EMBEDDING_SIZE\"], \n",
    "                                  return_sequences=True, \n",
    "                                  return_state=True, \n",
    "                                  recurrent_initializer='glorot_uniform', \n",
    "                                  activity_regularizer=L1L2(l1=0.000001, l2=0.000001))(historicals)\n",
    "    \n",
    "    print(cell)\n",
    "    \n",
    "    decoder = tf.keras.layers.LSTM(config[\"EMBEDDING_SIZE\"],\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform', \n",
    "                                   activity_regularizer=L1L2(l1=0.000001, l2=0.000001))(futures, initial_state=[hidden,cell])\n",
    "    \n",
    "    \n",
    "    encoder_outputs, hidden_state, cell_state = tf.keras.layers.LSTM(config[\"ENCODER_SIZE\"], \n",
    "                                                       return_sequences=True, \n",
    "                                                       return_state=True, \n",
    "                                                       recurrent_initializer='glorot_uniform', \n",
    "                                                       activity_regularizer=L1L2(l1=0.000001, l2=0.000001))(inputs)\n",
    "    \n",
    "    if(config[\"ATTENTION_MODULE\"] == \"additive\"):\n",
    "        if(config[\"ATTENTION_METHOD\"] == \"standard\"):\n",
    "            attention_layer = BahdanauAttentionLayer(config[\"ATTENTION_SIZE\"], use_bias=False)\n",
    "        elif(config[\"ATTENTION_METHOD\"] == \"vectorized\"):\n",
    "            attention_layer = BahdanauAttention(config[\"ATTENTION_SIZE\"], use_bias=False)\n",
    "        else:\n",
    "            raise Exception(f\"Invalid config ATTENTION_METHOD of {config['ATTENTION_METHOD']}\")\n",
    "    elif(config[\"ATTENTION_MODULE\"] == \"multiplicative\"):\n",
    "        if(config[\"ATTENTION_METHOD\"] == \"standard\"):\n",
    "            attention_layer = LuongAttentionLayer(config[\"ATTENTION_SIZE\"], use_bias=False)\n",
    "        elif(config[\"ATTENTION_METHOD\"] == \"vectorized\"):\n",
    "            attention_layer = LuongAttention(config[\"ATTENTION_SIZE\"], use_bias=False)\n",
    "        else:\n",
    "            raise Exception(f\"Invalid config ATTENTION_METHOD of {config['ATTENTION_METHOD']}\")\n",
    "    else:\n",
    "        raise Exception(f\"Invalid config ATTENTION_MODULE of {config['ATTENTION_MODULE']}\")\n",
    "    \n",
    "    decoder = tf.keras.layers.LSTM(config[\"DECODER_SIZE\"],\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform', \n",
    "                                   activity_regularizer=L1L2(l1=0.000001, l2=0.000001))\n",
    "    dropout = tf.keras.layers.Dropout(0.2)\n",
    "    decoder_output = tf.keras.layers.Dense(1)\n",
    "    all_outputs = []\n",
    "    last_value = tf.expand_dims(inputs[:, -1, 0:1], 1)\n",
    "    states = [hidden_state, cell_state]\n",
    "    for i in range(config[\"N_FWD\"]):\n",
    "        use_verbose = False\n",
    "        if(i == 0):\n",
    "            use_verbose=True\n",
    "        context_vector = attention_layer(query=tf.expand_dims(states[0],1), values=encoder_outputs, verbose=use_verbose)\n",
    "        decoder_input = tf.concat((last_value, context_vector), axis=-1)\n",
    "        x, hidden_state, cell_state = decoder(decoder_input, initial_state=states)\n",
    "        states=[hidden_state, cell_state]\n",
    "        x = dropout(x)\n",
    "        last_value = decoder_output(x)\n",
    "        all_outputs.append(last_value)\n",
    "    outputs = tf.keras.layers.Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss=\"mse\", metrics=[\"mae\"], optimizer=tf.keras.optimizers.Adam(learning_rate=config[\"LR\"]))\n",
    "    return model\n",
    "\n",
    "model = simple_encoder_decoder(X_train[0].shape[1:], X_train[1].shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126967"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    reducer = tf.keras.callbacks.ReduceLROnPlateau(monior='val_loss', factor=0.1, patience=2, mode='min', cooldown=1)\n",
    "    stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, mode='min', restore_best_weights=True)\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=config[\"BATCH_SIZE\"],\n",
    "              epochs=config[\"EPOCHS\"], \n",
    "              callbacks=[reducer, stopper, WandbCallback()],\n",
    "              validation_data=(X_val, y_val),\n",
    "              validation_batch_size=config[\"BATCH_SIZE\"],\n",
    "              shuffle=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for fold in range(1, 4):\n",
    "        run = wandb.init(project=\"time-series-methods\", entity=\"kmcguigan\", group=f\"{MODEL}-model\", config=config, job_type=\"train\")\n",
    "        run.name = f'{MODEL}-fold-{fold}'\n",
    "        X_train, y_train, X_val, y_val, _ = get_data(fold)\n",
    "        model = simple_encoder_decoder()\n",
    "        model = train_model(model, X_train, y_train, X_val, y_val)\n",
    "        run.finish()\n",
    "        del model\n",
    "        del X_train\n",
    "        del y_train\n",
    "        del X_val\n",
    "        del y_val\n",
    "        gc.collect()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\kiern\\MyFolders\\Code\\GitRepositories\\Time-Series-Playground\\wandb\\run-20220402_191130-o7660oed</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kmcguigan/time-series-methods/runs/o7660oed\" target=\"_blank\">zany-butterfly-14</a></strong> to <a href=\"https://wandb.ai/kmcguigan/time-series-methods\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2485/2485 [==============================] - 248s 76ms/step - loss: 0.3175 - mae: 0.4272 - val_loss: 0.1832 - val_mae: 0.3231 - lr: 0.0010 - _timestamp: 1648948552.0000 - _runtime: 262.0000\n",
      "Epoch 2/30\n",
      "2485/2485 [==============================] - 169s 68ms/step - loss: 0.1898 - mae: 0.3282 - val_loss: 0.1457 - val_mae: 0.2830 - lr: 0.0010 - _timestamp: 1648948721.0000 - _runtime: 431.0000\n",
      "Epoch 3/30\n",
      "2485/2485 [==============================] - 176s 71ms/step - loss: 0.1708 - mae: 0.3094 - val_loss: 0.1356 - val_mae: 0.2723 - lr: 0.0010 - _timestamp: 1648948896.0000 - _runtime: 606.0000\n",
      "Epoch 4/30\n",
      "2485/2485 [==============================] - 138s 55ms/step - loss: 0.1670 - mae: 0.3052 - val_loss: 0.1388 - val_mae: 0.2715 - lr: 0.0010 - _timestamp: 1648949034.0000 - _runtime: 744.0000\n",
      "Epoch 5/30\n",
      "2485/2485 [==============================] - 145s 58ms/step - loss: 0.1692 - mae: 0.3058 - val_loss: 0.1338 - val_mae: 0.2703 - lr: 0.0010 - _timestamp: 1648949179.0000 - _runtime: 889.0000\n",
      "Epoch 6/30\n",
      "2485/2485 [==============================] - 157s 63ms/step - loss: 0.1746 - mae: 0.3114 - val_loss: 0.1520 - val_mae: 0.2898 - lr: 0.0010 - _timestamp: 1648949336.0000 - _runtime: 1046.0000\n",
      "Epoch 7/30\n",
      "2485/2485 [==============================] - 160s 64ms/step - loss: 0.1602 - mae: 0.2976 - val_loss: 0.1347 - val_mae: 0.2680 - lr: 0.0010 - _timestamp: 1648949496.0000 - _runtime: 1206.0000\n",
      "Epoch 8/30\n",
      "2485/2485 [==============================] - 152s 61ms/step - loss: 0.1517 - mae: 0.2881 - val_loss: 0.1230 - val_mae: 0.2550 - lr: 1.0000e-04 - _timestamp: 1648949648.0000 - _runtime: 1358.0000\n",
      "Epoch 9/30\n",
      "2485/2485 [==============================] - 153s 61ms/step - loss: 0.1459 - mae: 0.2827 - val_loss: 0.1200 - val_mae: 0.2516 - lr: 1.0000e-04 - _timestamp: 1648949800.0000 - _runtime: 1510.0000\n",
      "Epoch 10/30\n",
      "2485/2485 [==============================] - 150s 60ms/step - loss: 0.1443 - mae: 0.2811 - val_loss: 0.1185 - val_mae: 0.2502 - lr: 1.0000e-04 - _timestamp: 1648949950.0000 - _runtime: 1660.0000\n",
      "Epoch 11/30\n",
      "2485/2485 [==============================] - 150s 60ms/step - loss: 0.1425 - mae: 0.2791 - val_loss: 0.1169 - val_mae: 0.2485 - lr: 1.0000e-04 - _timestamp: 1648950100.0000 - _runtime: 1810.0000\n",
      "Epoch 12/30\n",
      "2485/2485 [==============================] - 149s 60ms/step - loss: 0.1416 - mae: 0.2784 - val_loss: 0.1152 - val_mae: 0.2463 - lr: 1.0000e-04 - _timestamp: 1648950249.0000 - _runtime: 1959.0000\n",
      "Epoch 13/30\n",
      "2485/2485 [==============================] - 149s 60ms/step - loss: 0.1401 - mae: 0.2766 - val_loss: 0.1143 - val_mae: 0.2450 - lr: 1.0000e-04 - _timestamp: 1648950397.0000 - _runtime: 2107.0000\n",
      "Epoch 14/30\n",
      "2485/2485 [==============================] - 155s 62ms/step - loss: 0.1400 - mae: 0.2763 - val_loss: 0.1139 - val_mae: 0.2445 - lr: 1.0000e-04 - _timestamp: 1648950552.0000 - _runtime: 2262.0000\n",
      "Epoch 15/30\n",
      "2485/2485 [==============================] - 178s 71ms/step - loss: 0.1391 - mae: 0.2755 - val_loss: 0.1190 - val_mae: 0.2494 - lr: 1.0000e-04 - _timestamp: 1648950730.0000 - _runtime: 2440.0000\n",
      "Epoch 16/30\n",
      "2485/2485 [==============================] - 193s 78ms/step - loss: 0.1384 - mae: 0.2748 - val_loss: 0.1128 - val_mae: 0.2432 - lr: 1.0000e-04 - _timestamp: 1648950922.0000 - _runtime: 2632.0000\n",
      "Epoch 17/30\n",
      "2485/2485 [==============================] - 222s 89ms/step - loss: 0.1377 - mae: 0.2739 - val_loss: 0.1116 - val_mae: 0.2418 - lr: 1.0000e-04 - _timestamp: 1648951145.0000 - _runtime: 2855.0000\n",
      "Epoch 18/30\n",
      "2485/2485 [==============================] - 207s 83ms/step - loss: 0.1380 - mae: 0.2745 - val_loss: 0.1132 - val_mae: 0.2440 - lr: 1.0000e-04 - _timestamp: 1648951352.0000 - _runtime: 3062.0000\n",
      "Epoch 19/30\n",
      "2485/2485 [==============================] - 194s 78ms/step - loss: 0.1397 - mae: 0.2764 - val_loss: 0.1130 - val_mae: 0.2440 - lr: 1.0000e-04 - _timestamp: 1648951545.0000 - _runtime: 3255.0000\n",
      "Epoch 20/30\n",
      "2485/2485 [==============================] - 180s 72ms/step - loss: 0.1386 - mae: 0.2751 - val_loss: 0.1123 - val_mae: 0.2431 - lr: 1.0000e-05 - _timestamp: 1648951725.0000 - _runtime: 3435.0000\n",
      "Epoch 21/30\n",
      "2485/2485 [==============================] - 187s 75ms/step - loss: 0.1382 - mae: 0.2746 - val_loss: 0.1125 - val_mae: 0.2433 - lr: 1.0000e-05 - _timestamp: 1648951912.0000 - _runtime: 3622.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.225 MB of 0.225 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>███████▂▂▂▂▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>mae</td><td>█▃▃▂▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▄▃▅▃▂▂▂▂▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▅▄▄▃▅▃▂▂▂▂▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>16</td></tr><tr><td>best_val_loss</td><td>0.1116</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>loss</td><td>0.13819</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>mae</td><td>0.27462</td></tr><tr><td>val_loss</td><td>0.11247</td></tr><tr><td>val_mae</td><td>0.24331</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">zany-butterfly-14</strong>: <a href=\"https://wandb.ai/kmcguigan/time-series-methods/runs/o7660oed\" target=\"_blank\">https://wandb.ai/kmcguigan/time-series-methods/runs/o7660oed</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220402_191130-o7660oed\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\kiern\\MyFolders\\Code\\GitRepositories\\Time-Series-Playground\\wandb\\run-20220402_201212-20ailj3q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kmcguigan/time-series-methods/runs/20ailj3q\" target=\"_blank\">glad-puddle-15</a></strong> to <a href=\"https://wandb.ai/kmcguigan/time-series-methods\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3163/3163 [==============================] - 457s 120ms/step - loss: 0.3083 - mae: 0.4202 - val_loss: 0.2045 - val_mae: 0.3365 - lr: 0.0010 - _timestamp: 1648952408.0000 - _runtime: 476.0000\n",
      "Epoch 2/30\n",
      "3163/3163 [==============================] - 320s 101ms/step - loss: 0.1941 - mae: 0.3314 - val_loss: 0.1524 - val_mae: 0.2851 - lr: 0.0010 - _timestamp: 1648952729.0000 - _runtime: 797.0000\n",
      "Epoch 3/30\n",
      "3163/3163 [==============================] - 319s 101ms/step - loss: 0.1758 - mae: 0.3121 - val_loss: 0.1701 - val_mae: 0.2952 - lr: 0.0010 - _timestamp: 1648953047.0000 - _runtime: 1115.0000\n",
      "Epoch 4/30\n",
      "3163/3163 [==============================] - 326s 103ms/step - loss: 0.1587 - mae: 0.2959 - val_loss: 0.1437 - val_mae: 0.2724 - lr: 0.0010 - _timestamp: 1648953373.0000 - _runtime: 1441.0000\n",
      "Epoch 5/30\n",
      "3163/3163 [==============================] - 333s 105ms/step - loss: 0.1553 - mae: 0.2921 - val_loss: 0.1348 - val_mae: 0.2631 - lr: 0.0010 - _timestamp: 1648953706.0000 - _runtime: 1774.0000\n",
      "Epoch 6/30\n",
      "3163/3163 [==============================] - 546s 173ms/step - loss: 0.1482 - mae: 0.2850 - val_loss: 0.1310 - val_mae: 0.2576 - lr: 0.0010 - _timestamp: 1648954252.0000 - _runtime: 2320.0000\n",
      "Epoch 7/30\n",
      "3163/3163 [==============================] - 391s 124ms/step - loss: 0.1428 - mae: 0.2786 - val_loss: 0.1260 - val_mae: 0.2529 - lr: 0.0010 - _timestamp: 1648954643.0000 - _runtime: 2711.0000\n",
      "Epoch 8/30\n",
      "3163/3163 [==============================] - 400s 127ms/step - loss: 0.1551 - mae: 0.2898 - val_loss: 0.1267 - val_mae: 0.2518 - lr: 0.0010 - _timestamp: 1648955044.0000 - _runtime: 3112.0000\n",
      "Epoch 9/30\n",
      "3163/3163 [==============================] - 420s 133ms/step - loss: 0.1591 - mae: 0.2943 - val_loss: 0.1366 - val_mae: 0.2646 - lr: 0.0010 - _timestamp: 1648955464.0000 - _runtime: 3532.0000\n",
      "Epoch 10/30\n",
      "3163/3163 [==============================] - 429s 136ms/step - loss: 0.1432 - mae: 0.2792 - val_loss: 0.1305 - val_mae: 0.2562 - lr: 1.0000e-04 - _timestamp: 1648955893.0000 - _runtime: 3961.0000\n",
      "Epoch 11/30\n",
      "3163/3163 [==============================] - 437s 138ms/step - loss: 0.1398 - mae: 0.2754 - val_loss: 0.1239 - val_mae: 0.2498 - lr: 1.0000e-04 - _timestamp: 1648956330.0000 - _runtime: 4398.0000\n",
      "Epoch 12/30\n",
      "3163/3163 [==============================] - 471s 149ms/step - loss: 0.1368 - mae: 0.2723 - val_loss: 0.1221 - val_mae: 0.2470 - lr: 1.0000e-04 - _timestamp: 1648956801.0000 - _runtime: 4869.0000\n",
      "Epoch 13/30\n",
      "3163/3163 [==============================] - 466s 147ms/step - loss: 0.1347 - mae: 0.2699 - val_loss: 0.1243 - val_mae: 0.2497 - lr: 1.0000e-04 - _timestamp: 1648957267.0000 - _runtime: 5335.0000\n",
      "Epoch 14/30\n",
      "3163/3163 [==============================] - 485s 153ms/step - loss: 0.1339 - mae: 0.2690 - val_loss: 0.1197 - val_mae: 0.2440 - lr: 1.0000e-04 - _timestamp: 1648957752.0000 - _runtime: 5820.0000\n",
      "Epoch 15/30\n",
      "3163/3163 [==============================] - 428s 135ms/step - loss: 0.1327 - mae: 0.2676 - val_loss: 0.1219 - val_mae: 0.2471 - lr: 1.0000e-04 - _timestamp: 1648958180.0000 - _runtime: 6248.0000\n",
      "Epoch 16/30\n",
      "1379/3163 [============>.................] - ETA: 3:50 - loss: 0.1328 - mae: 0.2677"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
