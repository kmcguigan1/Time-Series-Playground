{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-28T03:49:23.391350Z","iopub.execute_input":"2022-03-28T03:49:23.391623Z","iopub.status.idle":"2022-03-28T03:49:23.408501Z","shell.execute_reply.started":"2022-03-28T03:49:23.391596Z","shell.execute_reply":"2022-03-28T03:49:23.407478Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"/kaggle/input/venezia/venezia.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1985.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1996.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1993.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1992.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1986.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2009.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1988.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2013.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2005.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2001.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1990.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1984.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2012.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1983.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1997.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2003.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1989.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1987.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1995.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2015.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2004.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1994.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1999.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2006.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2010.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2000.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2007.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1991.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_1998.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2002.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2011.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2014.csv\n/kaggle/input/venezia/Punta_Salute_1983_2015/Punta_Salute_2008.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.preprocessing import StandardScaler\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K","metadata":{"execution":{"iopub.status.busy":"2022-03-28T03:49:23.517998Z","iopub.execute_input":"2022-03-28T03:49:23.518287Z","iopub.status.idle":"2022-03-28T03:49:23.522983Z","shell.execute_reply.started":"2022-03-28T03:49:23.518258Z","shell.execute_reply":"2022-03-28T03:49:23.522296Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"N_PREV\": 90,\n    \"N_FWD\": 30,\n    \n    \"TEST_SIZE\": 0.1\n}","metadata":{"execution":{"iopub.status.busy":"2022-03-28T03:49:23.616113Z","iopub.execute_input":"2022-03-28T03:49:23.616991Z","iopub.status.idle":"2022-03-28T03:49:23.622896Z","shell.execute_reply.started":"2022-03-28T03:49:23.616939Z","shell.execute_reply":"2022-03-28T03:49:23.622253Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/venezia/venezia.csv')\ndf['datetime'] = pd.to_datetime(df['datetime'], infer_datetime_format=True)\ndf.sort_values(by='datetime', inplace=True, ignore_index=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T03:49:23.668703Z","iopub.execute_input":"2022-03-28T03:49:23.669283Z","iopub.status.idle":"2022-03-28T03:49:24.080218Z","shell.execute_reply.started":"2022-03-28T03:49:23.669245Z","shell.execute_reply":"2022-03-28T03:49:24.078998Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"             datetime  level\n0 1983-01-01 01:00:00   44.0\n1 1983-01-01 02:00:00   35.0\n2 1983-01-01 03:00:00   23.0\n3 1983-01-01 04:00:00   10.0\n4 1983-01-01 05:00:00    1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1983-01-01 01:00:00</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1983-01-01 02:00:00</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1983-01-01 03:00:00</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1983-01-01 04:00:00</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1983-01-01 05:00:00</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# values = df.datetime.values.astype('int64') // 10**9\n# ranges = values[1:]-values[:-1]\n# print(np.unique(ranges, return_counts=True))\n# print(np.where(ranges != 3600))\n# bad_indecies = [[x, x+1] for x in np.where(ranges!=3600)[0]]\n# print(bad_indecies)\n# # To make things easy we will drop any samples that have a pair of bad indecies","metadata":{"execution":{"iopub.status.busy":"2022-03-28T03:49:24.082176Z","iopub.execute_input":"2022-03-28T03:49:24.082680Z","iopub.status.idle":"2022-03-28T03:49:24.087992Z","shell.execute_reply.started":"2022-03-28T03:49:24.082634Z","shell.execute_reply":"2022-03-28T03:49:24.086937Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# do this stuff locally","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.values\ntss = TimeSeriesSplit(n_splits=5, test_size=int(df.shape[0]*config[\"TEST_SIZE\"]))\nfor train_idxs, test_idxs in tss.split(data):\n    final_train_sample = train_idxs[-1]\n    final_test_sample = test_idxs[-1]\n    print(final_train_sample, final_test_sample)\n    X_train, y_train = [], []\n    for i in range(final_train_sample-config[\"N_FWD\"]-config[\"N_PREV\"]):\n        X_train.append(data[i:i+config[\"N_PREV\"]])\n        y_train.append(data[i+config[\"N_PREV\"]:i+config[\"N_PREV\"]+config[\"N_FWD\"]])","metadata":{"execution":{"iopub.status.busy":"2022-03-28T03:50:19.375593Z","iopub.execute_input":"2022-03-28T03:50:19.375882Z","iopub.status.idle":"2022-03-28T03:50:20.865323Z","shell.execute_reply.started":"2022-03-28T03:50:19.375849Z","shell.execute_reply":"2022-03-28T03:50:20.864286Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"144636 173563\n173563 202490\n202490 231417\n231417 260344\n260344 289271\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}